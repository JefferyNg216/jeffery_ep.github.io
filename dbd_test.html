<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Jeffery's e-Portfolio - Deciphering Big Data</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">

							<!-- Logo -->
								<a href="index.html" class="logo">
									<span class="symbol"><img src="images/logo.svg" alt="" /></span><span class="title">Jeffery's e-Portfolio</span>
								</a>

							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>

						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>MSc of Data Science</h2>
						<ul>
							<li><a href="index.html">About Me</a></li>
							<li><a href="tdp.html">The Data Professional</a></li>
							<li><a href="na.html">Numerical Analysis</a></li>
							<li><a href="dbd.html">Deciphering Big Data</a></li>
							<li><a href="vd.html">Visualising Data</a></li>
							<li><a href="ml.html">Machine Learning</a></li>
							<li><a href="rmpp.html">Research Methods and Professional Practice</a></li>
							<!-- <li><a href="elements.html">Elements</a></li> -->
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<h1>Deciphering Big Data</h1>
							<span class="image main"><img src="images/pic13.jpg" alt="" /></span>
							<div><span lang=EN-GB><a
							href="#_LS"><span style='color:#1155CC'>Learning Summary</span></a></span></div>

							<div class=MsoNormal style='line-height:normal'><span lang=EN-GB>Activities:</span></div>

							<div class=MsoNormal style='margin-left:36.0pt;text-indent:-18.0pt;line-height:
							normal;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-GB><span
							style='mso-list:Ignore'>-<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
							</span></span></span><![endif]><span lang=EN-GB><span lang=EN-GB><a
							href="#_python"><span style='color:#1155CC'>Python</span></a></span></div>
							
							<div class=MsoNormal style='margin-left:36.0pt;text-indent:-18.0pt;line-height:
							normal;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-GB><span
							style='mso-list:Ignore'>-<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
							</span></span></span><![endif]><span lang=EN-GB><a
							href="#_normal"><span style='color:#1155CC'>Normalisation</span></a></span></div>

							<div class=MsoNormal style='margin-left:36.0pt;text-indent:-18.0pt;line-height:
							normal;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-GB><span
							style='mso-list:Ignore'>-<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
							</span></span></span><![endif]><span lang=EN-GB><a
							href="#_dbt"><span style='color:#1155CC'>Data Build Task</span></a></span></div>

							<div class=MsoNormal style='margin-left:36.0pt;text-indent:-18.0pt;line-height:
							normal;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-GB><span
							style='mso-list:Ignore'>-<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
							</span></span></span><![endif]><span lang=EN-GB><a
							href="#_api"><span style='color:#1155CC'>API Security</span></a></span></div>

							<div class=MsoNormal style='line-height:normal'><span lang=EN-GB><a
							href="#_fbda"><span style='color:#1155CC'>Future of Big Data Analytics</span></a></span></div>

							<div class=MsoNormal style='line-height:normal'><span lang=EN-GB><a
							href="#_reflect"><span style='color:#1155CC'>Reflection</span></a></span></div>

							<p>
							<p> <h1 style='line-height:0 '><a name="_LS"></a><span lang=EN-GB>Learning
							Summary</span></h1></p>

							<p style="margin-bottom: 10px;"><span>The &quot;Deciphering Big Data&quot; module provided a comprehensive exploration of the critical components and techniques used in managing and analyzing large datasets. Here is detailed summary of the key learnings from the module:</span></p >

							<u><span>Fundamental Concepts of Big Data:</span></u>
							<ul>
							    <li>
							        <p style="margin-bottom: 10px;"><span>Principles and Types of Big Data: Gained an understanding of the foundational concepts and diverse categories of big data, which are crucial for grasping the scale and complexity of data involved in modern analytics.</span></p>
							    </li>
								<li>
							        <p><span>Big Data Architectures: Explored various architectures that enable efficient processing and storage of big data.</span></p>
							    </li>
							</ul>

							<u><span>Data Characteristics and Manipulation:</span></u>
							<ul>
							    <li>
							        <p style="margin-bottom: 10px;"><span>Characteristics of Data Types and Formats: Examined the different types of data (structured, semi-structured, unstructured) and formats (e.g., CSV, JSON) that big data encompasses.</span></p>
							    </li>
								<li>
							        <p style="margin-bottom: 10px;"><span>Data Wrangling: Developed skills in transforming and mapping raw data into a more useful format, which is essential for further analysis.</span></p>
							    </li>
								<li>
							        <p><span>Parsing Source Data: Learned techniques for extracting data from common file formats used in business environments, such as Excel spreadsheets and PDF documents.</span></p>
							    </li>
							</ul>

							<u><span>Programming and Data Handling:</span></u>
							<ul>
							    <li>
							        <p style="margin-bottom: 10px;"><span>Data Handling with Python: Enhanced proficiency in using Python, a powerful programming language, for various big data operations including data manipulation and cleaning.</span></p>
							    </li>
								<li>
							        <p><span>Fact-Finding and Data Investigation: Cultivated the ability to conduct thorough investigations to uncover insights and validate data integrity throughout the analysis process.</span></p>
							    </li>
							</ul>

							<u><span>Web and Data Techniques:</span></u>
							<ul>
							    <li>
							        <p style="margin-bottom: 10px;"><span>Web Scraping: Acquired techniques for extracting data from the web, enabling the collection of real-time data from various online sources.</span></p>
							    </li>
								<li>
							        <p><span>Data Standardization and Normalisation: Learned methods to standardize and normalize data, ensuring consistency and accuracy in datasets.</span></p>
							    </li>
							</ul>

							<u><span>Advanced Data Analysis and Management:</span></u>
							<ul>
							    <li>
							        <p style="margin-bottom: 10px;"><span>Data Modeling: Gained insights into creating abstract models that organize elements of data and standardize how they relate to one another and to properties of the real world.</span></p>
							    </li>
								<li>
							        <p><span>DBMS Fundamentals and Structure: Studied the fundamental concepts and structures of Database Management Systems, essential for efficient data storage, manipulation, and retrieval. </span></p>
							    </li>
							</ul>

							<u><span>Compliance and Regulations:</span></u>
							<ul>
								<li>
							        <p><span>Compliance and Regulatory Frameworks: Explored the legal and ethical considerations in big data, understanding the importance of complying with data protection laws and regulations to safeguard information and maintain public trust.</span></p>
							    </li>
							</ul>

							</p>

							<p><h1 style='line-height:0'><a name="_python"></a><span lang=EN-GB>Python Activities:</span></h1></p>
							
							<p style="margin-bottom: 10px;"><span>Throughout the module, we explored a variety of data management techniques and functions in Python, including: </span></p >

							<ul>
							<li>NumPy<ul style="list-style-type: circle;margin-bottom: 0px;">
							<li><a href="dbd_link/link1.html" target="_blank" style='color:#1155CC'>Create NumPy array</a></li>
							<li><a href="dbd_link/link2.html" target="_blank" style='color:#1155CC'>Create an array of floating type elements</a></li>
							<li><a href="dbd_link/link3.html" target="_blank" style='color:#1155CC'>Adding Two NumPy Arrays</a></li>
							<li><a href="dbd_link/link4.html" target="_blank" style='color:#1155CC'>Mathematical Operations on NumPy Arrays</a></li>
							<li><a href="dbd_link/link5.html" target="_blank" style='color:#1155CC'>Advanced Mathematical Operations on NumPy Arrays</a></li>
							<li><a href="dbd_link/link6.html" target="_blank" style='color:#1155CC'>Generating Arrays Using arange and linspace</a></li>
							<li><a href="dbd_link/link7.html" target="_blank" style='color:#1155CC'>The Dimension, Shape, Size, and Data Type of the Two-dimensional Array</a></li>
							<li><a href="dbd_link/link8.html" target="_blank" style='color:#1155CC'>Zeros, Ones, Random, Identity Matrices, and Vectors</a></li>
							<li><a href="dbd_link/link9.html" target="_blank" style='color:#1155CC'>Reshaping, Ravel, Min, Max, and Sorting</a></li>
							<li><a href="dbd_link/link10.html" target="_blank" style='color:#1155CC'>Indexing and Slicing</a></li>
							<li><a href="dbd_link/link11.html" target="_blank" style='color:#1155CC'>Conditional Subsetting</a></li>
							<li><a href="dbd_link/link12.html" target="_blank" style='color:#1155CC'>Array Operations (array-array, array-scalar, and universal functions)</a></li>
							<li><a href="dbd_link/link13.html" target="_blank" style='color:#1155CC'>Stacking Arrays</a></li></ul></li>
							<li>Pandas Dataframe<ul style="list-style-type: circle;margin-bottom: 0px;">
							<li><a href="dbd_link/link14.html" target="_blank" style='color:#1155CC'>Pandas Series and Data Handling</a></li>
							<li><a href="dbd_link/link15.html" target="_blank" style='color:#1155CC'>Creating Pandas DataFrames</a></li>
							<li><a href="dbd_link/link16.html" target="_blank" style='color:#1155CC'>Viewing a DataFrame Partially</a></li>
							<li><a href="dbd_link/link17.html" target="_blank" style='color:#1155CC'>Indexing and Slicing Columns</a></li></ul></li>
							<li>Visualization with NumPy and Pandas<ul style="list-style-type: circle;margin-bottom: 0px;">
							<li><a href="dbd_link/link18.html" target="_blank" style='color:#1155CC'>Create simple scatter plots of age versus weight</a></li>
							<li><a href="dbd_link/link19.html" target="_blank" style='color:#1155CC'>Generating Random Numbers from a Uniform Distribution</a></li>
							<li><a href="dbd_link/link20.html" target="_blank" style='color:#1155CC'>Generating Random Numbers from a Binomial Distribution and Bar Plot</a></li>
							<li><a href="dbd_link/link21.html" target="_blank" style='color:#1155CC'>Generating Random Numbers from Normal Distribution and Histograms</a></li>
							<li><a href="dbd_link/link22.html" target="_blank" style='color:#1155CC'>Calculation of Descriptive Statistics from a DataFrame</a></li>
							<li><a href="dbd_link/link23.html" target="_blank" style='color:#1155CC'>Built-in Plotting Utilities</a></li></ul></li>
							<li>Subsetting, Filtering, and Grouping<ul style="list-style-type: circle;margin-bottom: 0px;">
							<li><a href="dbd_link/link24.html" target="_blank" style='color:#1155CC'>Loading and Examining a Superstore's Sales Data from an Excel File</a></li>
							<li><a href="dbd_link/link25.html" target="_blank" style='color:#1155CC'>Subsetting the DataFrame</a></li>
							<li><a href="dbd_link/link26.html" target="_blank" style='color:#1155CC'>Determining Statistics on Sales and Profit</a></li>
							<li><a href="dbd_link/link27.html" target="_blank" style='color:#1155CC'>The unique Function</a></li>
							<li><a href="dbd_link/link28.html" target="_blank" style='color:#1155CC'>Conditional Selection and Boolean Filtering</a></li>
							<li><a href="dbd_link/link29.html" target="_blank" style='color:#1155CC'>Setting and Resetting the Index</a></li>
							<li><a href="dbd_link/link30.html" target="_blank" style='color:#1155CC'>The GroupBy Method</a></li></ul></li>
							<li>Detecting Outliers and Handling Missing Values<ul style="list-style-type: circle;margin-bottom: 0px;">
							<li><a href="dbd_link/link31.html" target="_blank" style='color:#1155CC'>Indexing and Slicing Rows</a></li>
							<li><a href="dbd_link/link32.html" target="_blank" style='color:#1155CC'>Filling in the Missing Values with fillna</a></li>
							<li><a href="dbd_link/link33.html" target="_blank" style='color:#1155CC'>Dropping Missing Values with dropna</a></li>
							<li><a href="dbd_link/link34.html" target="_blank" style='color:#1155CC'>Outlier Detection Using a Simple Statistical Test</a></li></ul></li>
							<li>Concatenating, Merging, and Joining<ul style="list-style-type: circle;margin-bottom: 0px;">
							<li><a href="dbd_link/link35.html" target="_blank" style='color:#1155CC'>Concatenation</a></li>
							<li><a href="dbd_link/link36.html" target="_blank" style='color:#1155CC'>Merging by a Common Key</a></li>
							<li><a href="dbd_link/link37.html" target="_blank" style='color:#1155CC'>The join Method</a></li></ul></li>
							<li>Useful Methods of Pandas<ul style="list-style-type: circle;margin-bottom: 0px;">
							<li><a href="dbd_link/link38.html" target="_blank" style='color:#1155CC'>Randomised Sampling</a></li>
							<li><a href="dbd_link/link39.html" target="_blank" style='color:#1155CC'>The value_counts Method</a></li>
							<li><a href="dbd_link/link40.html" target="_blank" style='color:#1155CC'>Pivot Table Functionality</a></li>
							<li><a href="dbd_link/link41.html" target="_blank" style='color:#1155CC'>Sorting by Column Values</a></li>
							<li><a href="dbd_link/link42.html" target="_blank" style='color:#1155CC'>Flexibility for User-Defined Functions with the apply Method</a></li>
							<li><a href="dbd_link/link43.html" target="_blank" style='color:#1155CC'>Reading Data from Different Text-Based</a></li>
							<li><a href="dbd_link/link44.html" target="_blank" style='color:#1155CC'>Reading from a CSV File where Delimiters are not Commas</a></li>
							<li><a href="dbd_link/link45.html" target="_blank" style='color:#1155CC'>Bypassing the Headers of a CSV File</a></li>
							<li><a href="dbd_link/link46.html" target="_blank" style='color:#1155CC'>Skipping Initial Rows and Footers when Reading a CSV File</a></li>
							<li><a href="dbd_link/link47.html" target="_blank" style='color:#1155CC'>Reading Only the First N Rows</a></li>
							<li><a href="dbd_link/link48.html" target="_blank" style='color:#1155CC'>Combining Skiprows and Nrows to Read Data in Small Chunks</a></li>
							<li><a href="dbd_link/link49.html" target="_blank" style='color:#1155CC'>Setting the skip_blank_lines Option</a></li>
							<li><a href="dbd_link/link50.html" target="_blank" style='color:#1155CC'>Read CSV from a Zip file</a></li>
							<li><a href="dbd_link/link51.html" target="_blank" style='color:#1155CC'>Reading from an Excel File Using sheet_name and Handling a Distinct sheet_name</a></li>
							<li><a href="dbd_link/link52.html" target="_blank" style='color:#1155CC'>Reading a General Delimited Text File</a></li>
							<li><a href="dbd_link/link53.html" target="_blank" style='color:#1155CC'>Reading HTML Tables Directly from a URL</a></li>
							<li><a href="dbd_link/link54.html" target="_blank" style='color:#1155CC'>Further Wrangling to Get the Desired Data</a></li>
							<li><a href="dbd_link/link55.html" target="_blank" style='color:#1155CC'>Reading from a JSON File</a></li>
							<li><a href="dbd_link/link56.html" target="_blank" style='color:#1155CC'>Reading a Stata File</a></li>
							<li><a href="dbd_link/link57.html" target="_blank" style='color:#1155CC'>Reading Tabular Data from a PDF File</a></li></ul></li>
							<li>Beautiful Soup 4, Web Page Parsing and Web Scraping<ul style="list-style-type: circle;margin-bottom: 0px;">
							<li><a href="dbd_link/link58.html" target="_blank" style='color:#1155CC'>Reading an HTML file and Extracting its Contents Using BeautifulSoup</a></li>
							<li><a href="dbd_link/link59.html" target="_blank" style='color:#1155CC'>DataFrames and BeautifulSoup</a></li>
							<li><a href="dbd_link/link60.html" target="_blank" style='color:#1155CC'>Stacking URLs from a Document using bs4</a></li>
							<li><a href="dbd_link/link61.html" target="_blank" style='color:#1155CC'>Web Scraping</a></li></ul></li>
							</ul>

							<br>
							<p><h1 style='line-height:0'><a name="_normal"></a><span lang=EN-GB>Normalisation Activities:</span></h1></p>
							<ol>
							  <li>Here is a sample of the initial data before any normalization has been applied:</li>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/Normal_1.JPG" alt="" style="width: 400px; height: auto;" /></span>
							  <br>
							  <li>Second Normal Form (2NF): Next, we remove any partial dependencies. This involves ensuring that every non-prime attribute is fully functionally dependent on the primary key. In other words, each attribute must be associated directly and entirely with the primary key.</li>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/Normal_2.JPG" alt="" style="width: 400px; height: auto;" /></span>
							  <br>
							  <li>2NF - Remove partial dependency in which every non-prime attribute must be fully functionally dependent on the primary key</li>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/Normal_31.jpg" alt="" style="width: 400px; height: auto;" /></span>
							  <br>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/Normal_32.jpg" alt="" style="width: 400px; height: auto;" /></span>
							  <br>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/Normal_33.jpg" alt="" style="width: 400px; height: auto;" /></span>
							  <br>
							  <li>Following the application of 2NF, we noticed an issue in the course table related to "Exam Boards." Specifically, the relationship where the course name does not uniquely determine the exam boards (for example, the course "Maths" could be associated with both "EDExcel" and "AQA") indicated a violation of the Third Normal Form (3NF) due to transitive dependencies.<br>
							  <br>
							  Given this situation, it's feasible to address the requirements of both 2NF and 3NF simultaneously:-<br>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/Normal_41.jpg" alt="" style="width: 400px; height: auto;" /></span>
							  <br>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/Normal_42.jpg" alt="" style="width: 200px; height: auto;" /></span>
							  <br>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/Normal_43.jpg" alt="" style="width: 200px; height: auto;" /></span>
							  <br>
							  From the results obtained, we have successfully eliminated the transitive dependencies and demonstrated the appearance of the data structure following this integrated normalization process. This method guarantees that each table exclusively contains data that is directly related to the primary key, thus improving the integrity of the database and the efficiency of queries.<br>
							  </li>
							</ol>
							<br>
							<p><h1 style='line-height:0'><a name="_dbt"></a><span lang=EN-GB>Data Build Activities:</span></h1></p>
							Following the normalization exercise described above, we are now prepared to implement these changes at the database management system (DBMS) level.<br>
							<ol>
							  <li>Creating the ENROLLMENT table and simulating the 1NF table in the database.</li>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/db_1.jpg" alt="" style="width: 300px; height: auto;" /></span>
							  <br>
							  <li>Insert data at the atomic level into the table.</li>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/db_2.jpg" alt="" style="width: 600px; height: auto;" /></span>
							  <br>
							  <li>Implement a sequence for generating unique IDs.</li>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/db_3.jpg" alt="" style="width: 300px; height: auto;" /></span>
							  <br>
							  <li>Create the STUDENT, COURSE, and EXAM_BOARD tables, each equipped with a unique ID.</li>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/db_41.jpg" alt="" style="width: 600px; height: auto;" /></span>
							  <br>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/db_42.jpg" alt="" style="width: 600px; height: auto;" /></span>
							  <br>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/db_43.jpg" alt="" style="width: 600px; height: auto;" /></span>
							  <br>
							  <li>Establish the Enrolment table, linking it with corresponding IDs from the other tables.</li>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/db_51.jpg" alt="" style="width: 600px; height: auto;" /></span>
							  <br>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/db_52.jpg" alt="" style="width: 400px; height: auto;" /></span>
							  <br>
							  <li>With the ENROLLMENT table now featuring one primary key and three foreign keys, we can illustrate the relationships between these keys using a UML diagram as shown below:</li>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/db_6.jpg" alt="" style="width: 300px; height: auto;" /></span>
							  <br>
							  <li>Having established corresponding IDs from different tables, we can now merge this information. The SQL query to join these tables might look like this:</li>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/db_7.jpg" alt="" style="width: 600px; height: auto;" /></span>
							  <br>
							</ol>
							<p><h1 style='line-height:0'><a name="_api"></a><span lang=EN-GB>API Security Activities:</span></h1></p>
							Expanding on our grasp of data normalization techniques, it's equally imperative to prioritize API security. Given the prevalent use of APIs for data acquisition, safeguarding these interfaces is critical. APIs are vulnerable to a range of security threats that could undermine data integrity and confidentiality.<br>
							<br>
							To fortify API-driven applications against these vulnerabilities, a comprehensive security strategy is indispensable. This includes the deployment of robust security frameworks encompassing authentication, authorization, encryption, and consistent security evaluations. Such measures not only protect data but also bolster the reliability and credibility of API-dependent applications.<br>
							<br>
							When creating an API that supports data sharing, scraping, and connectivity across various formats, consider the following security protocols:<br>
							<br>
							Access Control <br>
							<li>Authentication: Secure credentials must accompany all API requests. Utilize API keys or OAuth tokens to regulate system access.</li>
							<li>Authorization: Implement role-based access control (RBAC) to restrict users to only those resources they are permitted to access, thereby averting unauthorized data alterations. </li>
							<br>
							Transaction Security<br>
							<li>Transport Security: Mandate TLS 1.2 or higher encryption for all data in transit, safeguarding sensitive information from unauthorized interception.</li>
							<li>Input Validation: Rigorously validate all inputs, particularly those accepting XML or JSON, against a schema to thwart injection attacks and maintain data integrity.</li>
							<li>Output Encoding: Ensure that data output in SQL, XML, or JSON formats is correctly encoded to prevent injection attacks in various contexts.</li>
							<br>
							Performance Control<br>
							<li>Rate Limiting: Implement rate limiting to defend against denial-of-service (DoS) attacks and prevent resource depletion.</li>
							<li>Logging and Monitoring: Keep comprehensive logs of access and errors. Set up real-time monitoring and alerts to detect and respond to suspicious activities promptly.</li>
							<li>Incident Response: Develop a clear incident response strategy to quickly and effectively handle security breaches.</li>
							<br>
							These detailed specifications are designed to reduce risks associated with unauthorized access, data breaches, and service interruptions, thereby establishing a secure and reliable API environment for efficient data exchange.<br>
							<br>
							<p><h1 style='line-height:0'><a name="_fbda"></a><span lang=EN-GB>Future of Big Data Analytics</span></h1></p>
							Finally, this module has explored diverse perspectives on the future of big data analytics. The exponential growth of big data in today's world is undeniable, and its effective management and utilization are pivotal for driving decision-making processes across various sectors. As technology evolves, so too does the landscape of data management, necessitating a deep understanding of which data is useful and how to extract meaningful insights from massive datasets. Overall, this can be divided into four sections:-<br>
							<br>
							<u>Technological Advancements in Data Management</u><br>
							Emerging database technologies are reshaping how we store, retrieve, and manage data. Distributed databases facilitate the spreading of data across various locations, enhancing accessibility and efficiency. Object-oriented databases, which store data as objects, offer flexibility and reusability in application development, while image and hypertext databases support the storage and complex querying of non-traditional data formats such as images and interconnected text. Furthermore, graph databases represent a significant shift from traditional relational databases by efficiently mapping complex, interconnected data structures. These technologies reflect a move towards more dynamic, flexible data management systems that can handle the increasing variety and volume of data.<br>
							<br>
							<u>Machine Learning: A Tool for Data Utilization</u><br>
							Machine learning stands as a cornerstone technology in the realm of big data. By training algorithms on vast datasets, patterns and relationships can be discerned, leading to predictive insights that can significantly influence strategic decisions. For instance, in retail, machine learning enables basket analysis to identify purchasing patterns and optimize cross-selling opportunities. In finance, it supports risk assessment for loan approvals by analyzing borrower data against historical outcomes. This capability of machine learning to process and analyze large datasets efficiently not only enhances operational efficiency but also drives innovation across industries.<br>
							<br>
							<u>Best Practices and Reflective Research in Big Data</u><br>
							Adhering to best practices in big data management is crucial. Initiatives should start small but think big, focusing on high-value opportunities that can gradually scale. Avoiding common pitfalls such as overpromising results or neglecting to integrate business insights into technological solutions is essential for sustainable success. <br>
							<br>
							Moreover, reflective research activities are vital for maintaining objectivity and relevance in data analysis. Understanding the specific data needs of an organization and how these relate to achieving business goals ensures that data strategies are aligned with business outcomes. This involves continuous learning and adaptation to new technologies and methodologies, such as integrating advanced data processing technologies like Hadoop and Spark, and exploring emerging fields like blockchain for data integrity and security. <br>
							<br>
							<u>Ethical and Strategic Considerations</u><br>
							<br>
							As we harness the power of big data, ethical considerations and strategic planning become paramount. Ensuring privacy, securing data, and following regulatory guidelines are not just legal necessities but also critical to maintaining public trust and organizational integrity. Furthermore, the integration of AI and machine learning into data analytics must be approached with a clear understanding of both the potential and the limitations of these technologies.<br>
							<br>
							In Conclusion, the future of big data is intrinsically linked to continuous technological innovation and the strategic foresight of businesses. Leveraging machine learning for data analysis, adopting new database technologies, and maintaining rigorous best practices will be essential for organizations aiming to derive value from their data assets. As big data continues to grow, so too will the opportunities for businesses to innovate, optimize operations, and enhance decision-making processes through data-driven insights. Reflective, ethical research and the application of comprehensive data management strategies will ensure that the use of big data contributes positively to technological advancement and business success.<br>
							<br>
							<br>							
							<h1 style='line-height:0'><a name="_reflect"></a><span lang=EN-GB>Reflection</span></h1>
							<u>Introduction</u><br>
							As we reach the end of this module, I've noticed that it differed from others, primarily due to the inclusion of a group assignment. Collaborating with my peers was not only interesting but also enriched my learning experience significantly. In this reflection assignment, I will use Gibbs' Reflective Cycle to outline my journey through the module and highlight the insights gained.<br>
							<br>
							<u>Review and Evaluation </u><br>
							The primary objective of the module was to deepen our understanding of Big Data, focusing on its analysis, transformation into actionable insights, and efficient storage solutions. Throughout the course, we explored a variety of methodologies, technologies, and programming tools designed to enhance our ability to handle large datasets effectively. Key concepts introduced included the Four V's of Big Data, which provide a framework for understanding its complexities; the data wrangling process, which prepares raw data for analysis; and techniques for data scraping and cleaning using Python. Additionally, we delved into data normalisation and modelling to ensure data integrity, and we studied advanced database structures to optimise data storage and retrieval. This comprehensive approach has equipped us with the necessary skills to process and manage Big Data in a professional context.<br>
							<br>
							For our assignment in Unit 6, we were tasked with developing a proposal for constructing a database for a specific area. Leveraging my background that spans both business and technical domains, I was well-equipped to define the comprehensive requirements for this project. This included delineating the logical flow of the system, identifying necessary attributes, and selecting appropriate and scalable technology for the database construction.<br>
							<br>
							Throughout the development of this proposal, I integrated the knowledge acquired from the module with practical insights from my professional experience. This synthesis allowed me to meticulously plan and outline the steps necessary for the database build, which are as follows:<br>
							<br>
							<ol>
							  <li>Conceptualise the Operational Flow:</li>
							  Visualise how the system will operate and start by considering the initial dimensions of the database.<br>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/ref_1.jpg" alt="" style="width: 300px; height: auto;" /></span>
							  <br>
							  <li>Define the Data Dictionary:</li>
							  Outline the necessary attributes, detailing each attribute¡¦s role and significance within the database.<br>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/ref_2.jpg" alt="" style="width: 300px; height: auto;" /></span>
							  <br>
							  <li>Evaluate the Data Dictionary Structure:</li>
							  Assess the structure of the data dictionary to ensure clarity and functionality.<br>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/ref_3.jpg" alt="" style="width: 300px; height: auto;" /></span>
							  <br>
							  <li>Draft the Logical Flow:</li>
							  Create a preliminary version of the logical flow, mapping out how data will move and interact within the system.<br>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/ref_4.jpg" alt="" style="width: 300px; height: auto;" /></span>
							  <br>
							  <li>Finalise the Logical Flow:</li>
							  Refine the draft to ensure that the logical flow is efficient and that it aligns seamlessly with the corresponding attributes.<br>
							  <span class="image main" style="margin-bottom: 10px;"><img src="dbd_image/ref_5.jpg" alt="" style="width: 300px; height: auto;" /></span>
							</ol>
							This structured approach not only streamlined the proposal process but also ensured that the proposed database design would be robust, efficient, and capable of evolving with future business needs. <br>
							<br>
							For the executive summary, it offers a comprehensive evaluation of the database development from its inception. Initially, I revisited the design and thoroughly assessed its strengths and weaknesses. This critical review pinpointed four primary areas for improvement that are essential for optimising the database's effectiveness and efficiency:<br>
							<br>
							<ol>
							  <li>Content Enhancement:</li>
							  <ul>
							  <li>Broaden the scope of attributes across various dimensions to comprehensively enhance the data warehousing process. This expansion is not only about increasing the quantity of data but also about enriching the quality of information captured.</li>
							  <li>Proactively design the database to accommodate future enterprise expansion. This includes making the database flexible and scalable to handle increased data volumes and new types of data as the business evolves.</li>
							  </ul>
							  <li>Structure Enhancement:</li>
							  <ul>
							  <li>Refine the initial design to enhance risk assessment strategies, thereby minimising the risk of data loss.</li>
							  <li>Strengthen the database architecture to function effectively as a disaster recovery site based on the improved structure. This ensures that the system supports business continuity plans, maintaining operations even under adverse conditions.</li>
							  </ul>
							  <li>Cost Efficiency and Alternatives:</li>
							  <ul>
							  <li>Conduct a thorough evaluation of the cost-effectiveness of the current database construction. This analysis should consider not only the initial costs but also long-term operational expenses.</li>
							  <li>Offer alternative strategies to the enterprise, based on the enhanced model, which could provide more value or reduce costs.</li>
							  </ul>
							  <li>Compliance:</li>
							  <ul>
							  <li>Address compliance issues by advising on key regulations pertinent to the database.</li>
							  <li>Advise the enterprise for necessary actions to ensure compliance with these regulations.</li>
							  </ul>
							</ol>
							This executive summary does more than just review the database's scope; it actively delivers strategic recommendations and alternatives to significantly enhance the enterprise's operations. By addressing the gaps identified in the initial proposal, the summary ensures the development of a robust, scalable, and compliant database system that is prepared to meet current and future challenges. This approach not only strengthens the database's foundational aspects but also aligns it more closely with the enterprise's strategic objectives. <br>
							<br>
							<u>Conclusion, Feelings and Action Plan</u><br>							
							Reflecting on the roadmap and assessments from the module, I initially anticipated a straightforward experience given its close alignment with my job responsibilities. However, as I delved deeper into the coursework, my perspective shifted. This wasn't merely about ease or familiarity; despite the relevance of my existing skills, the module introduced numerous theoretical concepts and techniques that enriched my professional practice.<br>
							<br>
							This educational journey highlighted the importance of humility in learning. It reminded me that revisiting familiar theories and technologies can uncover new insights or previously overlooked details. This approach not only broadened my understanding but also opened opportunities for personal and professional growth. It has taught me the value of maintaining an open and humble mindset towards continuous learning, enabling me to enhance my work and approach known subjects with a fresh perspective.<br>
							<br>
							Furthermore, the group assessment also proved to be a valuable experience, differing significantly from my usual approach. Typically, I prefer to lead projects with a clear plan in mind, executing tasks quickly and adhering strictly to the outlined strategy. This method, while efficient, sometimes results in less collaboration and can inadvertently create friction among team members.<br>
							<br>
							Through this group assessment, I recognized the need to adjust my approach. It became clear that actively listening to others' opinions is crucial. Everyone's perspective is not only valid but also necessary, as it mirrors the process of revisiting familiar knowledge at different stages, potentially sparking innovative and insightful ideas.<br>
							<br>
							Overall, this experience has not only been a lesson in the technical aspects of my field but also in the essential patterns and attitudes necessary for continuous learning and effective collaboration. It has reinforced the importance of adaptability, openness, and respect for diverse viewpoints in my professional development. Moving forward, I am committed to applying these principles to foster an inclusive and innovative work environment, ensuring both personal and team growth.<br>
							<br>
						</div>
					</div>

				<!-- Footer -->
					<!-- <footer id="footer">
						<div class="inner">
							<section>
								<h2>Get in touch</h2>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<input type="text" name="name" id="name" placeholder="Name" />
										</div>
										<div class="field half">
											<input type="email" name="e mail" id="email" placeholder="Email" />
										</div>
										<div class="field">
											<textarea name="message" id="message" placeholder="Message"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send" class="primary" /></li>
									</ul>
								</form>
							</section>
							<section>
								<h2>Follow</h2>
								<ul class="icons">
									<li><a href="#" class="icon brands style2 fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="#" class="icon brands style2 fa-facebook-f"><span class="label">Facebook</span></a></li>
									<li><a href="#" class="icon brands style2 fa-instagram"><span class="label">Instagram</span></a></li>
									<li><a href="#" class="icon brands style2 fa-dribbble"><span class="label">Dribbble</span></a></li>
									<li><a href="#" class="icon brands style2 fa-github"><span class="label">GitHub</span></a></li>
									<li><a href="#" class="icon brands style2 fa-500px"><span class="label">500px</span></a></li>
									<li><a href="#" class="icon solid style2 fa-phone"><span class="label">Phone</span></a></li>
									<li><a href="#" class="icon solid style2 fa-envelope"><span class="label">Email</span></a></li>
								</ul>
							</section>
							<ul class="copyright">
								<li>&copy; Untitled. All rights reserved</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer> -->

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
